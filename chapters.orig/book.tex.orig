\documentclass{article}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{ifthen}
\usepackage{calc}
\usepackage{wrapfig}
\usepackage{algpseudocode}
\usepackage{colortbl,booktabs}

\setlength{\textwidth}{6in}
\setlength{\oddsidemargin}{.5\oddsidemargin}
\pagestyle{fancy}

\newcommand{\cf}[1]{\texttt{#1}}
\newcommand\cind{5mm}
\newcommand\cmd[1]{\textbf{#1}}

\begin{document}

\section{Expected Contents}

\begin{itemize}
\item Historical perspective
\subitem How Linux evolved from other architectures
\item Filesystem concepts
\item File concepts
\subitem mmap 
\subitem What have I missed over the years?
\item Debugging and tracing concepts
\item File I/O
\subitem System calls relating to file I/O (open, read, write, close, dup, …)
\subitem Standard Library - buffered I/O
\subitem Asynchronous I/O
\item Filesystem concepts
\subitem Pseudo filesystems 
\subitem Physical filesystems 
\subitem Network filesystems 
\subitem FUSE-based
\subitem Containers?
\subitem User created namespaces
\item Backup / restore?
\item What Linux filesystems exist today?
\item Structures in the kernel and how user space stuff maps to them
\item Shared stuff
\item Getting ready to develop a filesystem
\subitem Kernel source
\subitem Debugging
\subitem Module development
\subitem eBPF and other tools
\item Developing a physical filesystem
\item Developing a FUSE-based filesystem
\end{itemize}

\tableofcontents

\section{Introduction}

My first introduction to an operating system kernel came in 1985 when one of the XXX at Leeds University (in the UK) gave an informal walkthrough of the BSD XYZ kernel source code. At this time, the BSD source code could be found on every system under /sys (check). I believe that the machine we were using was a DEC PDP-11. It was also around this time that Kernighan and Ritchie’s The C Programming Language was one of the few books available about C. If you wanted to learn about UNIX, Kernighan and Pike’s The UNIX Programming Environment was the book of choice having just been launched the year I started college. Both are now available free on-line.

I was lucky to work on the Chorus Microkernel early during my career while I was at ICL (International Computers Limited), the UK’s largest mainframe manufacturer. After working on European research projects around Chorus, we started to work on enhancing the SVR4 UNIX subsystem running on top of the microkernel which involved porting the VERITAS filesystem (VxFS) and volume manager (VxVM). I worked on the latter. Due to the very different interactions between filesystems and the virtual memory (VM) subsystems of both Chorus MiX (their version of SVR4) and vanilla SVR4 UNIX, the port of the filesystem was an enormous job. The volume manager less so (lucky for me). Over those years I gained an insight into the operations of both kernels and my love of 
filesystems started.

In 1993 I joined SCO (the Santa Cruz Operation) partly to help them to switch over from an SVR3 UNIX Filesystem Switch (FSS) architecture to support the Sun/USL VFS/vnode based architecture. As with ICL, we were looking to modernize our filesystem support and bring in filesystems such as VxFS which were light years ahead of anything on UNIX variants at that time. Two things prevented that move. First, the cost of rewriting large parts of the kernel were prohibitive. Secondly, the cost of converting existing filesystems over to a new VFS/vnode architecture would also add significant expense. And on top of that, SCO acquired the rights to UNIX and they now had SVR4 UNIX in their hands.

I led the SCO kernel architecture team whose job it was to look at more forward looking features, new architectures like the upcoming RISC-based Intel P6 which was abandoned following their agreement with HP (more details). We also started investigating a new microkernel-based architecture to replace European telecom proprietary operating systems.

\begin{wrapfigure}{L}{0.3\textwidth}
	\centering
	\includegraphics{figures/book-1.jpg}
\end{wrapfigure}

While running the architecture team, I wrote my first book covering SCO UNIX internals. At that time, it was a much enhanced version of SVR3 UNIX. We’d abandoned the idea of SVR4 VFS/vnodes but had implemented support for a journaling filesystem from a US east coast company called Prologic. We also completely rewrote the VM subsystem to support mmap(2) and subsequent support of the SVR4 development environment (compiler etc). Much of that work was done by Hugh Dickens who went on to make many contributions to the Linux kernel.

I was proud of what I’d accomplished. It’s not easy to write about a proprietary operating system but started my journey in writing in as practical a way as possible. The book has many programming examples and use of crash(1) to display the contents of kernel structures after user-space commands are run and system calls are made.

Around this time, I was also working on the Chorus microkernel as part of a consortium between SCO, Chorus and Siemens Private Networks. At first this was an SVR3-based UNIX subsystem running on Chorus but that was switched to SVR4. Once again we started porting VxFS and VxVM over to the microkernel but made better choices to largely emulate SVR4 interfaces to simplify the port. And then SCO abandoned the project and started spiraling downwards. At this time, I left the UK and joined VERITAS to work in Mountain View, California. It was 
interesting, but at that time, SGI were building all around the area. Years later, the vast majority of their buildings were taken over by Google.

As a side note, SCO used to hold SCO Forum each summer at UC Santa Cruz. I pulled together a panel session to talk about the future of operating systems and managed to get Bill Shannon (Sun employee 11), Michel Gien (co-founder of Chorus Systemes), someone representing the Mach microkernel whose name escapes me and Linus Torvalds. Linus was still living in Finland at the time so we flew him over to California to spend the week with us. Unfortunately I have no photos of the event.

\begin{wrapfigure}{L}{0.3\textwidth}
	\centering
	\includegraphics{figures/book-2.jpg}
\end{wrapfigure}

As an operating system enthusiast, the VERITAS filesystem was a great place to work. The VERITAS filesystem VxFS ran on a number of different operating systems. I initially started working on the portability project where we tried to share as much code as possible VxFS on UnixWare, HP-UX and Solaris. Later on we added AIX and I ran the team that ported VxFS to Linux. 

While at VERITAS I wrote my second book. This one covered filesystems from a variety of different UNIX and UNIX-like operating systems. I included a sample Linux filesystem similar to the kernel-based filesystem presented in this book. At the time, this was for the 2.4.x kernel and a lot has changed since then.

After working at two unsuccessful startups, I worked for Vormetric where I was later CTO. They were an encryption and key management company that encrypted at both the filesystem and volume layers, also for a wide array of operating systems (Solaris, AIX, HP-UX, Linux and Windows). I then spent the next 14 years working on encryption and key management technologies in the two startups I co-founded, HyTrust and HighCloud Security.

That brings us to the present day and back to book writing but now full time. I looked to see what material was out there about Linux filesystems and surprised to see that there was a gap that needed to be filled. And thus, I started coding again for the first time in years (apart from writing Space Invaders in Python/pygame) with the goal to build simple filesystems that are easy to explain and play with.

Lastly, this book is allowing me to achieve something I've wanted to do for many years and that is to write it and typeset it using \LaTeX which I have used for many years. I typeset my first two books. My first book was written using Microsoft Word which actually worked fine but struggled with such a large number of pages. I was disappointed with FrameMaker when typesetting my second book. The program just didn't seem as simple and easy to use as it did when I used the early versions of FrameMaker on my old Sun Sparcstation 1. 

\subsection{Do you do anything for fun?}

I've been an avid sports fan all my life playing almost every sport you can think of mostly football/soccer in my early years. We run (several half marathons under my belt), hike the mountains around Tucson, Arizona, do yoga and cycle a lot. When I turned 50, I completed 50 rides of 50+ miles. At the time I'm writing this we're gearing up for the metric century for the Tour de Tucson. Not bad for a vegan of 35 years!

My favorite teams are Newcastle United, San Francisco Giants, San Francisco 49ers and the Oregon Ducks (my daughter went to college there).

Oh and I'm a great fan of beer, growing up with Newcastle Brown Ale and British Bitters but having developed more of a taste for IPAs over the last several years.

\section{Conventions}

I try to follow man page sections when commands, libraries and system calls are referenced. So \cf{umount(1)} refers to the \cf{umount} command while \cf{umount(2)} refers to the system call. If \cf{umount} is used without a section reference it refers more to one or the other but generally just during the time when the filesystem is being unmounted.

Internal functions such as those used by SPFS are given quotes but have no corresponding man page. An example would be \cf{sp\_read\_inode()}.

\pagebreak
\section{Coding Standards}

\begin{verbatim}
- POSIX - https://www.opengroup.org/austin/papers/posix_faq.html
- Single UNIX Specification - https://collaboration.opengroup.org/platform/single_unix_specification/documents.php?action=show&gdid=9045 
- and ... https://collaboration.opengroup.org/platform/single_unix_specification/documents.php?action=show&gdid=9634
- Linux Standard Base - https://en.wikipedia.org/wiki/Linux_Standard_Base
\end{verbatim}

\noindent
Not so long ago there were many different operating systems out there which made programming across them difficult if it wasn't for a set of standards. The number of different types of operating systems has certainly declined as the following figure shows.

\noindent
So do standards matter and if I want to write an application, what interfaces should I used? Furthermore, if I am ony interested in having my application run across the different versions of Linux, what should I use?

TBD

\pagebreak
\section{The Linux System Call Interface}

What is a system call? When writing applications you use library functions which may directly call the kernel, sometimes might not and sometimes might. How about that for confusing?. For a simple program such as the one below, you may unaware of difference (error checking excluded for simplicity):

\begin{Verbatim}
    #include <fcntl.h>
    #include <stdio.h>
    #include <unistd.h>

    int
    main()
    {
        int fd;

        fd = open("msg", O_CREAT | O_WRONLY);
        write(fd, "hello world\n", 12);
    }
\end{Verbatim}

\noindent
By searching for the \cf{open()} or \cf{write()} functions you will see multiple options. Here, I'm displaying a subset of what is shown when searching for write-related functions and commands. Here we can see a command called \cf{write} as indicated by the \cf{(1)} and the \cf{write} system call as indicated by the \cf{(2)}.

\begin{Verbatim}[commandchars=\\\{\}]
    $ \cmd{man -k write}
    aio_write (3)        - asynchronous write
    write (1)            - send a message to another user
    write (2)            - write to a file descriptor
\end{Verbatim}

\noindent
So what do those numbers represent? The UNIX (and now Linux) manual pages is divided . To see the list of available sections, run \cf{man man}. Here are the sections fro Linux:

\begin{Verbatim}
       1   Executable programs or shell commands
       2   System calls (functions provided by the kernel)
       3   Library calls (functions within program libraries)
       4   Special files (usually found in /dev)
       5   File formats and conventions, e.g. /etc/passwd
       6   Games
       7   Miscellaneous (including  macro  packages  and  conventions),  e.g.
           man(7), groff(7), man-pages(7)
       8   System administration commands (usually only for root)
       9   Kernel routines [Non standard]
\end{Verbatim}

\noindent
If you want to see the man page for the \cf{write()} system call, run "\cf{man 2 write}".

In linux-5.19/arch/x86/entry/syscalls there are tables for 32/64-bit (syscall\_32.tbl \&	syscall\_64.tbl)

For reference https://0xax.gitbooks.io/linux-insides/content/SysCall/ is a good source. 

There are a lot of system calls. In fact, 322 for x86\_64 and 358 for x86. How many of these are related to filesystem activity? \textbf{XXX}---do the calculation some day.

\begin{Verbatim}[commandchars=\\\{\}]
    $ \cmd{grep SYSCALL_DEFINE3 *c | wc -l}
       56
\end{Verbatim}

It's actually close to 41!!! Above command shows duplicates and other stuff.

\noindent
To understand the mapping between a user space program and the kernel system call interface, let's go back to our program which creates a file and writes the string \cf{"hello world$\backslash$n"} to it:

Try \cf{objdump -d hello} and see where the system call is. Compare to the x86 version referenced above.

I often use the Elixir Cross Referencer (https://elixir.bootlin.com/linux/latest/source) as I can look at different versions of Linux and it's nice to have this in conjunction with \cf{vim} where I tend to bang away at keys (lack of touch typing skills). But with Elixir, it's not easy to find the right system call unless you know what you're looking for. How can we resolve that?

Most (all?) file/filesystem related system calls can be found in the \cf{kernel/fs} directory. The easiest way to find them is to run \cf{grep SYSCALL\_DEFINE3 *.c} and you'll see that the file/filesystem functions are spread across 16 files. Here are some examples looking for specific function calls.

\begin{Verbatim}[commandchars=\\\{\}]
    $ \cmd{grep 'SYSCALL_DEFINE3(write' *.c}
    read_write.c:SYSCALL_DEFINE3(write, unsigned int, fd, ...
    read_write.c:SYSCALL_DEFINE3(writev, unsigned long, fd, ...
    $ \cmd{grep 'SYSCALL_DEFINE3(read' *.c }
    read_write.c:SYSCALL_DEFINE3(read, unsigned int, fd, ...
    read_write.c:SYSCALL_DEFINE3(readv, unsigned long, fd, ...
    stat.c:SYSCALL_DEFINE3(readlink, const char __user *, path, ...
    $ \cmd{grep 'SYSCALL_DEFINE3(fcntl' *.c}
    fcntl.c:SYSCALL_DEFINE3(fcntl, unsigned int, fd,  ...
    fcntl.c:SYSCALL_DEFINE3(fcntl64, unsigned int, fd, ...
    fcntl.c:COMPAT_SYSCALL_DEFINE3(fcntl64,  ...
    fcntl.c:COMPAT_SYSCALL_DEFINE3(fcntl, unsigned int, fd, ...
\end{Verbatim}

\noindent
Most of these top-level functions don't do very much (read above links for more details) but you'll see the function that does the real work. For example, in the case of the \cf{write(2)} system call, a call is made to \cf{ksys\_write()} as follows:

\begin{Verbatim}
    SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,
            size_t, count)
    {
        return ksys_write(fd, buf, count);
    }
\end{Verbatim}

\noindent
And then from the top level Linux source tree I can run the following to get to the right function (users of Emacs and other editors will have similar ways to get there quickly):

\begin{Verbatim}[commandchars=\\\{\}]
     $ \cmd{vi -t ksys\_write}
\end{Verbatim}

\noindent
Different people have different preferences in how they navigate through the kernel source. The \cf{cscope(1)} command is another tool that you can look at. Since I often wish to walk through filesystem-related system calls, I built a little script that displays various routines. After choosing an option, it switches to the top of the kernel source tree where it assumes you have a tags file and then enters \cf{vi} at the appropriate place. The advantage here is that I can now use tag stacking to move through the specific function deeper into the kernel. \cf{XXX}---have a link to my website showing how to use tag stacking.

Here is a shorter version of the bash script. It's very simple.

\begin{Verbatim}
    TAGS_DIR=~/src/linux-5.19

    echo "
    1 - read
    2 - write
    q - quit
    "

    cd $TAGS_DIR
    while :
    do
        /bin/echo -n "System call? "
        read choice
        case $choice in
            1) vi -t ksys_read ;;
            2) vi -t ksys_write ;;
            q) break ;;
            *) echo "Invalid choice"
        esac
    done
\end{Verbatim}

\section{Linux Kernel Structures for File Access}

Figure \ref{fig:per-file-kernel-structures} shows the main structures in the kernel for accessing files. It all starts with a file descriptor that the application gets back from \cf{open(2)} and friends.

\begin{figure}
	\centering
	\includegraphics[scale=0.6]{figures/per-file-kernel-structures.pdf}
	\caption{Filesystem layout on disk}
	\label{fig:per-file-kernel-structures}
\end{figure}

\noindent
Although the figure implies that \cf{fd} points to the \cf{task\_struct}. Once upon a time in older versions of UNIX, the file descriptor was an index into an array of \cf{struct file} elements held within the \cf{proc} structure (the equivalent of Linux's \cf{task\_struct}). This allowed for a fixed number of open files, a restriction that continued through to SVR3 UNIX. At SCO, although we had an SVR3-based version of UNIX, this limit was removed to allow for a more dynamic (and tunable) number of open files. This was similar in the first version of Linux which had the following field in the \cf{task\_struct}:

\begin{Verbatim}
    struct file * filp[NR\_OPEN];
\end{Verbatim}

\noindent
and \cf{NR\_OPEN} was defined as 20. 

\subsection{File-related System Calls}

When you want to look at a symlink and not follow through the link use \cf{lstat(2)} rather than \cf{stat(2)}

\pagebreak
\section{Building a Kernel-based Filesystem}

There are two ways to understand filesystems. Either you can study one of more of the 80+ existing filesystems or you can develop one. The issue with studying existing filesystems is that they all have their peculiarities which 
make analyzing the source code more complicated. For example, I’ve looked at BFS which is a simple filesystem developed for UNIX SVR4 (System V Release 4) for the \cf{/stand} filesystem. It’s a filesystem I worked with many years ago. It only has 1200 lines of kernel source code but still has a few twists. It’s background:

It was designed to hold all binaries needed during the boot phase. It’s simple disk layout helped with simplifying the boot loader which didn’t need to know about the structure of more complex filesystems such as UFS and VxFS which were commonplace on SVR4 at the time. As such it was not designed for general purpose usage.

\begin{itemize}
	\item It’s a flat filesystem (only files within a single root directory). 
	\item Only regular files can be created. You can't create symbolic links.
	\item Files are allocated contiguously, again to simplify boot. This makes writing files more complex since blocks need to be moved to retain this requirement.
	\item XXX - anything else?
\end{itemize}

\noindent
It would be better to have a simple filesystem without these limitations but with a goal of keeping it about the same size in terms of lines of code. I developed such a filesystem for my first book (UNIX Filesystems - Design and 
Implementation) in 2003 for the Linux 2.4 kernel. I’ve used that as a base (things have changed quite a bit since) but hopefully made it easier to understand by adding more tracing and fixing some bugs that slipped under the 
rug. This new filesystem is called SPFS (no prizes for guessing the name).

Here are the main characteristics of SPFS:

\begin{itemize}
	\item Multi-level directories (directories within directories removing the BFS limitation)
	\item Fixed block size (1024 bytes).
	\item A filename length up to 28 characters.
	\item 470 blocks within the whole filesystem (240 KB).
	\item A maximum file size of 247 KB.
\end{itemize}

\noindent
Most of these limitations are in place to keep the on-disk structures very simple which result in the code to access them being much easier to understand. The goal here is for teaching.

\subsection{The SPFS on-disk Format}

As discussed earlier, simplicity is key. We are not trying to design a high-performing, crash-resistant filesystem but one with the simplest structure and the least amount of code (around 2,000 lines including \cf{mkfs}, \cf{fsdb} and lots of debug messages and debug ioctls.

The filesystem block size for SPFS is 1024 bytes. If we have a regular file with size of 0, it will have no allocated blocks. If the size of the file is <= 1024 bytes it will have 1 block. If the size of the file is 1025 bytes it will have 2 blocks allocated and so on. The same is true for directories. There is never an empty directory because a newly allocated directory will always have entries for "." and "..". Directory entries are 32 bytes so a new directory will have one allocated 1024 byte block and a size of 64 bytes.

The superblock is limited to one block due to the way superblocks are accessed as part of mount processing. Since this structure maintains a list of used/unused inodes and blocks in the filesystem, this is where our limitation of the filesystem size and number of files comes from. To increase the size of the superblock beyond 1024 bytes would add additional complexity which we are trying to avoid.

There are three components to the disk layout as shown in figure \ref{fig:fslayout}.

\begin{figure}
	\centering
	\includegraphics[scale=0.6]{figures/fslayout.pdf}
	\caption{Filesystem layout on disk}
	\label{fig:fslayout}
\end{figure}

\begin{enumerate}
	\item \textbf{Superblock} --- this is stored in block 0.
	\item \textbf{Inodes} --- stored in blocks 8-49. There is one inode per block. This is not efficient in terms of 
		space but as we shall see later, locating the block where the inode is stored is very simple. It’s just 
		block 8 + inode number. For example, the root inode is stored at block 10. There can only be 32 files in 
		the filesystem and since inodes 0, 1 aren't used and inode 2 is for the root directory, there are only
		29 files that can be created.
	\item \textbf{Data blocks} --- stored from block 50 onwards. Data blocks are used for regular file data as well 
		and directory entries for directories and symbolic links. 
\end{enumerate}

\subsection{From Module Load to Mounting a Filesystem}

In \ref{fig:module-load} we show which functions are called as part of loading the module (and unloading) and how the filesystem’s mount function is identified to the kernel and called.

\begin{figure}
	\includegraphics[scale=0.6]{figures/module-load.pdf}
	\centering
	\caption{Module Initialization}
	\label{fig:module-load}
\end{figure}

First of all we declare our filesystem module through the \cf{file\_system\_type} structure (shown in gray). Here we have:

\begin{itemize}
	\item The name of the filesystem.
	\item The filesystem’s \cf{mount} function that should be called when a filesystem of type \cf{spfs} 
	         is mounted (\cf{mount -t spfs}).
	\item The function that should be called during \cf{umount } processing to clean up everything. 
		XXX - need to figure out if anything is left other than setting the SB to CLEAN and flushing it.
\end{itemize}

\noindent
There are two functions declared:

\begin{itemize}
	\item \cf{init\_spfs\_fs()} - this will be called when the module is loaded (either 
		\cf{insmod} or \cf{mount -t spfs} - XXX need to figure out the MODULE\_ALIAS\_FS(“spfs") stuff
	\item \cf{exit\_spfs\_fs()} - this is called when the module is unloaded (\cf{rmmod}).
\end{itemize}

\noindent
When the module is loaded, the first thing that \cf{init\_spfs\_fs()} performs is to register the file system by calling \cf{register\_filesystem()}. The main goal of this function is to check that the filesystem has not already been registered. If not, it is added to the list of available filesystems as shown in figure \ref{fig:filesystems-available} . XXX - need to check this with a debugger to show how many filesystems and make sure spfs is last on the list.

\begin{figure}[h]
	\includegraphics[scale=0.6]{figures/filesystems-available.pdf}
	\centering
	\caption{The list of available Linux filesystems that can be mounted}
	\label{fig:filesystems-available}
\end{figure}

\cf{file\_systems} can be found in fs/filesystems.c next to \cf{register\_filesystem()} and associated functions.

When issuing a \cf{mount -t spfs} call, the kernel can walk through this list checking the \cf{spfs} argument against the name field of each \cf{file\_system\_type} structure in the list. If there is a match, the kernel can locate the filesystem-specific mount function and call it.

\subsection{Initializing the per-filesystem Inode Cache}

Every filesystem has its own \cf{init\_inodecache()} function for maintaining a list of per-filesystem inodes (all mounts?). When allocating a Linux inode, a call is made to \cf{alloc\_inode\_sb()} (linux/fs.h) where they say:

\begin{quote}
\it This must be used for allocating filesystems specific inodes to set up the inode reclaim context correctly.
\end{quote}

\noindent
When creating or opening a file, a Linux inode is created. There is one inode regardless of the number of open file descriptors. To populate many of the fields of the inode, the kernel requests the filesystem to allocate the inode. For existing files, this involves reading the corresponding SPFS inode from disk. Much of the information about the file is used to populate the Linux inode but there is some information that SPFS must also keep in-core. This information relates to where the data blocks for the file are stored on disk (all file types---regular, directories and symlinks) and how many blocks have been allocated so far.

Here is both the SPFS in-core inode and the SPFS disk inode. The Linux inode is embedded within the SPFS in-core inode. All inodes for this mounted filesystem are referenced from the \cf{super\_block} structures as shown in figure \ref{fig:inode-lru-list}.

\begin{Verbatim}[xleftmargin=\cind]
struct sp_inode_info {
    int           i_blocks;
    int           i_addr[SP_DIRECT_BLOCKS];
    struct inode  vfs_inode;  
};
\end{Verbatim}

\noindent
The disk-based inode contains more fields. All but the last two fields are copied to the Linux inode so there is no point replicating them in the in-core SPFS inode.

\begin{Verbatim}[xleftmargin=\cind]
struct sp_inode {
    __u32	i_mode;
    __u32	i_nlink;
    __u32	i_atime;
    __u32	i_mtime;
    __u32	i_ctime;
    __u32	i_uid;
    __u32	i_gid;
    __u32	i_size;
    __u32	i_blocks;
    __u32	i_addr[SP_DIRECT_BLOCKS];
};

#define ITOSPI(inode)   (struct sp_inode_info *)&inode->i_private
\end{Verbatim}

\begin{figure}
	\includegraphics[scale=0.6]{figures/inode-lru-list.pdf}
	\centering
	\caption{Inode LRU List referenced from the \cf{super\_block} structure}
	\label{fig:inode-lru_list}
\end{figure}

\noindent
Many calls into SPFS pass the Linux inode. We often need to access the SPFS in-core inode which we can do through use of the \cf{ITOSPI()} macro. We'll discuss how this LRU list is used later on in the book XXX.

\subsection{Mounting a Filesystem}

When a filesystem is mounted, the filesystem type is passed as an argument, for example:

\begin{Verbatim}[commandchars=\\\{\}]
    # \cmd{mount -t spfs /dev/sdb1 /mnt}
\end{Verbatim}

\noindent
The kernel uses this argument to find the correct \cf{file\_system\_type} structure (see figure \ref{fig:filesystems-available}) and call the filesystem’s mount function. Recall that this is one of the fields in struct \cf{file\_system\_type} and was passed to the kernel during module load by calling \cf{register\_filesystem()}.

Here are the set of calls (viewable using \cf{dmesg}) made from the kernel into SPFS to complete the mount call. The root inode of the filesystem is inode 2.

\bigskip
\cf{spfs\_mount()} $\rightarrow$ \cf{spfs\_fill\_super()}  $\rightarrow$ \cf{sp\_read\_inode()} (inode number 2)
\\~\\
\noindent
Following a call to mount, any operation on this filesystem must start with the root directory and thus, the kernel will call the \cf{super\_block read\_inode()} function to read the root inode in from disk.

Need a figure of kernel structures for this

Xxx

\subsubsection{Inside sp\_mount and sp\_fill\_super}

The code for \cf{spfs\_mount()} is very simple, relying solely on a call to \cf{mount\_bdev()}. It passes \cf{spfs\_fill\_super()} as as argument.

\begin{Verbatim}[xleftmargin=\cind]
static struct dentry *
spfs_mount(struct file_system_type *fs_type, int flags, 
	           const char *dev_name, void *data)
{
    return mount_bdev(fs_type, flags, dev_name, data, spfs_fill_super);
}
\end{Verbatim}

\noindent
After calling \cf{spfs\_fill\_super()} the following structures are linked together as shown in figure ref{fig:per-mount-structures}.

\begin{figure}
	\includegraphics[scale=0.6]{figures/sp_fill_super.pdf}
	\centering
	\caption{Per-mount structures following a call to \cf{sp\_fill\_super()}}
	\label{fig:per-mount-structures}
\end{figure}

\noindent
At this point we have enough structure in place to allow us to do the following type of operations:

\begin{itemize}
	\item Get filesystem information (think calling the \cf{df} command) through use of 
		 the \cf{sp\_statfs()} function.
	\item List the contents of the root directory (\cf{i\_fop} points indirectly to  
	         \cf{sp\_readdir()}).
	\item Lookup files to start traversing the filesystem (\cf{i\_fop} points indirectly 
		to \cf{sp\_lookup()}).
\end{itemize}

\noindent
As we progress through the filesystem, more inodes will be read into memory and from there we can perform all the basic filesystem operations. XXX - we’ll expand …

For the moment, let’s look more at \cf{sp\_fill\_super()} ...

\subsection{super\_operations}

So we have a separation from mount and unmount (see module loading section below)

\begin{Verbatim}[xleftmargin=\cind]
static const struct super_operations spfs_sops = {
    .alloc_inode. = sfs_alloc_inode,
    .free_inode.  = sfs_free_inode,
    .write_inode  = sfs_write_inode,
    .evict_inode  = sfs_evict_inode,
    .put_super    = sfs_put_super,
    .statfs       = sfs_statfs,
};
\end{Verbatim}

\noindent
Any of the operations that your filesystem provides are called by the kernel once the filesystem is mounted.

bfs\_put\_super() doesn’t do much other than free the structure. I guess because this is a read-only FS? It was similar for uxfs which is incomplete as we don’t set the CLEAN/DIRTY flag in the superblock correctly. XXX - see what others are doing here

\subsection{Unmounting}

When issuing the \cf{umount} system call, there can be a lot of data in-core that needs to be written to disk. Let's start with an example of calls that are made to SPFS

\begin{Verbatim}[commandchars=\\\{\}]
    # \cmd{mount -t spfs /mnt}
    # \cmd{mkdir /mnt/mydir}
    # \cmd{mkdir /mnt/mydir/next_dir}
    # \cmd{umount /mnt}
\end{Verbatim}

\noindent
Just looking at the operations, you can see that we will create two new inodes for the directories that we're creating and we will also make modifications to the root directory. Since we have allocated two new inodes and corresponding data blocks to store their directory entries, we have also made changes to the SPFS superblock.

\begin{Verbatim}[xleftmargin=\cind]
sp_write_inode (ino=4)	- /mnt/mydir
sp_write_inode (ino=2)	- root
sp_write_inode (ino=5)	- /mnt/mydir/next_dir

sp_evict_inode - nlink > 0 (ino=2)
sp_evict_inode - nlink > 0 (ino=4)
sp_evict_inode - nlink > 0 (ino=5)

sp_put_super

sp_free_inode (ino=2)
sp_free_inode (ino=4)
sp_free_inode (ino=5)
\end{Verbatim}

\noindent
XXX - Why is evict being called if we've already done write\_inode?

In all 3 cases, inode-> i\_count = 0 and this is a check that is made from evict\_inodes() (fs/inode.c) - this is called by generic\_shutdown\_super() which then calls put\_super(). It gets complicated here so we shall have to revisit.

\begin{verbatim}
kill_anon_super() -> generic_shutdown_super() -> evict and put_super
\end{verbatim}

\subsection{Creating a File}

Before we explore reading and writing files, file creation has several interactions between the kernel and SPFS. Let's view the calls that the kernel makes in response to:

\begin{Verbatim}
    # mount -t spfs /dev/sda /mnt
    # touch /mnt/myfile
    # umount /mnt
\end{Verbatim}

\noindent
The \cf{touch(1)} command will invoke the \cf{openat(2)} system call as follows:

\begin{Verbatim}
    openat(AT_FDCWD, "/mnt/myfile1", 
           O_WRONLY|O_CREAT|O_NOCTTY|O_NONBLOCK, 0666)
\end{Verbatim}

\noindent
The \cf{penat(2)} system call is identical to  \cf{open(2)}  except that the path argument is interpreted relative to the starting point implied by the first argument. If this argument has the special value \cf{AT\_FDCWD}, the filename argument will be resolved relative to the current working directory. If the path argument is absolute, the first argument is ignored. This is irrelevant in this case as we're specifying the full pathname. \textbf{XXX} need to come back to this at some point.

Figure \ref{fig:create-file} show the calls made into SPFS in response to a request to create a new file.

\begin{figure}
	\includegraphics[scale=0.6]{figures/create-file.pdf}
	\centering
	\caption{Calls into SPFS when creating a file}
	\label{fig:create-file}
\end{figure}

\noindent
The root directory inode (now at \cf{/mnt}) was instantiated during mount processing so the kernel can query using this inode. If you recall, when a directory inode is instantiated, SPFS attaches the following operations to the \cf{i\_op} field of the Linux inode.

\begin{Verbatim}
    struct inode_operations sp_dir_inops = {
        create:              sp_create,
        lookup:              sp_lookup,
        mkdir:               sp_mkdir,
        rmdir:               sp_rmdir,
        link:                sp_link,
        unlink:              sp_unlink,
    };
\end{Verbatim}

\noindent
The first call that the kernel makes into SPFS when creating a file is \cf{sp\_lookup()} on the root inode (directory). It passes \cf{myfile} as an argument in addition to the directory inode and a dentry to associate with the file whether it exists or not. In turn, \cf{sp\_lookup()} calls \cf{sp\_find\_entry()} to scan the list of directory entries for the specified directory. As expected, this fails since the file does not exist. Before returning, \cf{sp\_lookup()} will call \cf{d\_splice\_alias(inode, dentry)} to create a negative dentry for \cf{myfile}. If another lookup operation were to occur on this file, the kernel now knows that the file doesn't exist. 

The kernel then calls \cf{sp\_create()} to now create the file. Once \cf{sp\_create()} creates the new file, it calls \cf{d\_instantiate(dentry, inode)} to map the entry for \cf{myfile} to the inode just created.

\subsubsection{Inside \cf{sp\_find\_entry()}}

This function is called to locate a file in the specified directory  inode. Before we show the source code, let's assume that the root directory has 96 entries. The disk structure for this would resemble figure \ref{fig:sp-filldir}.

\begin{figure}
	\includegraphics[scale=0.6]{figures/sp-filldir.pdf}
	\centering
	\caption{The root directory with 96 entries}
	\label{fig:sp-filldir}
\end{figure}

When the filesystem is created, we allocate block 50 as the first data block of the root inode. This is stored in the \cf{i\_addr} field of the on-disk inode. Inside the actual data block we write directory entries for ".", ".." and "lost+found". As time goes by and new files are created, we will also add them to block 50 until there is no more space. At this point, we allocated a new block (\cf{i\_addr[1] = 58}) and start adding the new directory entries in this block. And so on. A simplified form of the algorithm to search for a directory entry is:

When the filesystem is created, we allocate block 50 as the first data block of the root inode. This is stored in the \cf{i\_addr} field of the on-disk inode. Inside the actual data block we write directory entries for ".", ".." and "lost+found". As time goes by and new files are created, we will also add them to block 50 until there is no more space. At this point, we allocated a new block (\cf{i\_addr[1] = 58}) and start adding the new directory entries in this block. And so on. A simplified form of the algorithm to search for a directory entry is:


\noindent
\begin{algorithmic}
\For{each allocated block in the inode}
\For{all 32 directory entries in the block}
\If{the name to find matches the name in this entry}
\State return the inode number found in this entry
\EndIf
\EndFor
\EndFor
\State return 0 /* we didn't find an entry */
\end{algorithmic}

\bigskip
\noindent
The code for \cf{sp\_find\_entry()} is shown below. If the root directory had 3 allocated blocks as shown in figure \ref{fig:sp-filldir} we would require reading 3 1024 byte blocks from disk before we determine that the file does not exist.

\begin{Verbatim}
    int
    sp_find_entry(struct inode *dip, char *name)
    {
        struct sp_inode_info    *spi = ITOSPI(dip);
        struct super_block      *sb = dip->i_sb;
        struct buffer_head      *bh;
        struct sp_dirent        *dirent;
        int                     i, blk = 0;

        for (blk=0 ; blk < spi->i_blocks ; blk++) {
            bh = sb_bread(sb, spi->i_addr[blk]);
            dirent = (struct sp_dirent *)bh->b_data;
            for (i=0 ; i < SP_DIRS_PER_BLOCK ; i++) {
                if (strcmp(dirent->d_name, name) == 0) {
                    brelse(bh);
                    return dirent->d_ino;
                }
                dirent++;
            }
        }
        brelse(bh);
        return 0;
    }
\end{Verbatim}

\noindent
If the file is found, we return its inode number (allowing for a subsequent call to read the inode from disk). If it is not found, we return 0. \cf{XXX}---recall that inode number 0 is not used. For this reason.

\subsubsection{Inside \cf{sp\_create\_file()}}

There are 3 different types of file creation in SPFS. Although we are covering regular file creation, we'll touch on the other two since all three operations share common paths. Let's take a look at what's needed for each but first, what is needed for all 3:

\begin{itemize}
	\item Allocate an inode on disk resulting in superblock changes.
	\item Allocate a Linux in-core inode together with its corresponding in-core SPFS inode.
	\item Update fields of both inodes to specify file properties.
	\item Write the SPFS inode to disk.
	\item Flush the superblock to disk to reflect the changes after everything else is done.
\end{itemize}

\noindent
For each of the 3 operations, there are things that are unique to the file type that we must take care of:
		
\begin{enumerate}
	\item Creating a regular file.
		\begin{itemize}
			\item Nothing. Just make sure the size of the file (\cf{i\_size}) is set to 0.
		\end{itemize}
	\item Creating a directory.
		\begin{itemize}
			\item Allocate a block for initial directory entries ("." and "..").
			\item Write this block to disk.
			\item Update inode properties ((\cf{i\_size} = 2 * (\cf{sizeof(struct sp\_direct)}, 
				\cf{i\_blocks} = 1)
		\end{itemize}
	\item Creating a symbolic link.
		\begin{itemize}
			\item Allocate a block to store the target name
			\item Write this block to disk.
			\item Update inode properties ((\cf{i\_size} = 2 * (\cf{sizeof(struct sp\_direct)}, 
				\cf{i\_blocks} = 1)
		\end{itemize}
\end{enumerate}

\noindent
Having said all of that, the core for (\cf{sp\_create\_file()} is very simple:

\begin{Verbatim}
    int
    sp_create(struct user_namespace *mnt_userns, struct inode *dip,
              struct dentry *dentry, umode_t mode, bool excl)
    { 
        struct inode    *inode;
        char            *name = (char *)dentry->d_name.name;
        int             error;
                
        inode = sp_new_inode(dip, dentry, S_IFREG | mode, NULL);
        if (IS_ERR(inode)) {
            error = PTR_ERR(inode);
            goto out;
        }
    out:        
        return error;
    }
\end{Verbatim}

\noindent
We simply rely on a call to \cf{sp\_new\_inode()} to do all of the work. The source code for \cf{sp\_mkdir()} and \cf{sp\_symlink()} is almost identical. The exception is the last argument to \cf{sp\_new\_inode()} which we will cover during the section on symlinks (\textbf{XXX}).

\subsubsection{Inside \cf{sp\_new\_inode()}}

\noindent
\begin{algorithmic}
\For{each allocated block in the inode}
\For{all 32 directory entries in the block}
\If{the name to find matches the name in this entry}
\State return the inode number found in this entry
\EndIf
\EndFor
\EndFor
\State return 0 /* we didn't find an entry */
\end{algorithmic}

\subsubsection{Inside \cf{sp\_ialloc()}}

There are two fields in the SPFS superblock (in-core and on disk) that record how many inodes have been allocated (\cf{s\_nifree} and which inodes have been allocated (the array cf{s\_inode}. 

\begin{Verbatim}
    ino_t
    sp_ialloc(struct super_block *sb)
    {
        struct spfs_sb_info  *sbi = SBTOSPFSSB(sb);
        int                   i;
    
        if (sbi->s_nifree == 0) {
            printk("spfs: Out of inodes\n");
            return 0;
        } else {
            mutex_lock(&sbi->s_lock);
            for (i = 4 ; i < SP_MAXFILES ; i++) {
                if (sbi->s_inode[i] == SP_INODE_FREE) {
                    sbi->s_inode[i] = SP_INODE_INUSE;
                    sbi->s_nifree--;
                    mutex_unlock(&sbi->s_lock);
                    return i;
                }
            }
        }
    }
\end{Verbatim}

\noindent
We check up front if any inodes are available. If not we return 0. If there is at least one inode available, we grab the SPFS superblock lock and walk through the array. As soon as we find an entry marked free, we set it to \cf{SP\_INODE\_INUSE}, drop the superblock lock and return.

\subsubsection{More on Negative dentries}

As mentioned above, when a call is made to \cf{sp\_lookup()}, the file \cf{myfile} does not exist so a negative dentry is created. In our example, the kernel follows up with a call to \cf{sp\_create()} so why is this necessary? There are times that a request will be made to test for the presence of a file as the following example shows:

\begin{Verbatim}[commandchars=\\\{\}]
    \cmd{# stat /mnt/myfile}
    stat: cannot statx '/mnt/myfile': No such file or directory
\end{Verbatim}

\noindent
In figure \ref{fig:create-file} steps 1 and 2 will be performed by the kernel to see if the file exists. This will more than likely result in the filesystem reading from disk and there could be multiple reads depending on how many directories exist. Since the file does not exist, it returns \cf{ENOENT} and retains the negative dentry.

If another \cf{stat(1)} call is made, the kernel doesn't need to call the filesystem again since it now knows that the file does not exist. And thus the role of negative dentries.

\subsection{Obtaining Filesystem Information via statfs}

The \cf{df(1)} command displays information about each mounted filesystem. Here is the information displayed by \cf{df} for a newly created and mounted SPFS filesystem:

\begin{Verbatim}[commandchars=\\\{\}]
    # \cmd{df -h /mnt}
    Filesystem      Size  Used Avail Use% Mounted on
    /dev/sda        440K   52K  388K  12% /mnt
\end{Verbatim}

\noindent
Refer to figure \ref{fig:fslayout} for how an SPFS filesystem is laid out.

You'll see in \cf{spfs.h} that \cf{SP\_MAXBLOCKS} is 470 and  \cf{SP\_BSIZE} is 1024 and thus the size of the filesystem is 440k. The first data block starts at block 50 and blocks 50 and 51 are used for directory entries for the root directory and \cf{lost+found}. 

The \cf{df} command uses the \cf{statfs(2)} system call to gather information for each mounted filesystem. This results in a call to \cf{sp\_statfs()} to get the necessary information for a specific mount. This function is very straightforward returning some defaults and some information about the filesystem that is kept in the in-core \cf{sp\_superblock} structure.

\begin{Verbatim}
    buf->f_type = SP_MAGIC;
    buf->f_bsize = SP_BSIZE;
    buf->f_blocks = SP_MAXBLOCKS;
    buf->f_bfree = sbi->s_nbfree;
    buf->f_bavail = sbi->s_nbfree; 
    buf->f_files = SP_MAXFILES; 
    buf->f_ffree = sbi->s_nifree;
    buf->f_fsid = u64_to_fsid(huge_encode_dev(sb->s_bdev->bd_dev));
    buf->f_namelen = SP_NAMELEN;
\end{Verbatim}

\noindent
Note that \cf{f\_bfree} and \cf{f\_bavail} are both set to the number of free blocks available. SPFS does not draw a distinction between the two:

\begin{itemize}
	\item \cf{f\_bfree}---Free blocks in filesystem
	\item \cf{f\_bavail}---Free blocks available to unprivileged user
\end{itemize}

\noindent
XXX it would be good to see who actually sets these differently

More complex filesystems won't use as many defaults and the filesystem size will vary as well as the block size and the number of files available (potentially). But even with more complex filesystems, such information will be held in an in-core superblock or other such structure. 

\subsection{Hard Links and Symbolic Links}

Implementing support for symbolic links turned out to be much harder than I'd ever have thought with a lot of kernel panics and confusion on my part. I'll explain the approach I took to get this working then will further discuss the different options later (section \cf{XXX}).

First I decided to keep it simple and store the symlink in a data block and read it in when requested. This is the old style way of storing symlinks since space inside the inode has generally been at a premium. With a disk-based inode where I'm storing disk blocks, I'd rather have more blocks, and therefore a larger file size, than space for a symlink since symlinks are used much less frequently. This method of storing symlinks within their own disk blocks is called "slow symlinks" due to the disk access.

But I soon ran into a problem trying to get it to work after umount/mount.

\begin{Verbatim}
static const struct inode_operations sysv_symlink_inode_operations = {
    .get_link   = page_get_link,
    .getattr    = sysv_getattr,
};
\end{Verbatim}

\noindent
For symlinks read 

\begin{itemize}
	\item https://www.halolinux.us/kernel-reference/lookup-of-symbolic-links.html 
	\item https://www.kernel.org/doc/Documentation/filesystems/porting.rst
	\item https://unix.stackexchange.com/questions/147535/fast-and-slow-symlinks
\end{itemize}

\noindent
When creating a new inode for a symlink, a call is made as follows:

\begin{Verbatim}
    page_symlink(inode, symlink_target, slen);
\end{Verbatim}

\noindent
This kernel function gets the address space operations we attached to the new inode and calls:

\begin{Verbatim}
    aops->write_begin(NULL, mapping, 0, len-1, &page, &fsdata);
    memcpy(page_address(page), symname, len-1);
    aops->write_end(NULL, mapping, 0, len-1, len-1, page, fsdata);
    mark_inode_dirty(inode);
\end{Verbatim}

\noindent
{\bf NOTE}---you must hash an inode before making it dirty otherwise making it dirty later won't work. I was calling \cf{page\_symlink()} before calling \cf{insert\_inode\_hash()} and so the inode never gets marked dirty. This is done in sp\_new\_inode(). I set up each inode by type (reg,dir,lnk) and then call \cf{mark\_inode\_dirty()} but symlinks are different due to the call to \cf{page\_symlink()} which internally calls cf{mark\_inode\_dirty()}.


\section{Debugging Kernel Panics}

If you're doing development in the kernel you'll get used to kernel panics which can occur for a number of reasons (\cf{XXX} - list some). While developing SPFS, I ran into kernel panics when implementing support for symbolic links. I managed to create the symlink fine but doing an \cf{ls -l} on the directory where the symlink resided, resulted in a panic when trying to read the contents of the symlink (what file it was pointing to).

XXX

\subsection{Exploring File/Filesystem Information with eBPF}

We've covered several tools for exploring file/filesystem related information up to this point. Another method is to use eBPF, the enhanced Berkeley Packet Filter technology that has been in the Linux kernel since {\bf XXX}.

\section{Extended SPFS Filesystem}

A list of topics that we’ll add EPFS:

\begin{itemize}
	\item Hard links and symlinks - talk about dentries and inodes 
	      (i\_nlink always being 1 if there are no links)
	\item Bitmaps for inode tables
	\item Indirect blocks
	\item fsck?
	\item Talk about testing. I keep changing things and breaking them!!!
	\item Talk about tracing and why this is good - avoid duplication 
	      such as call to sp\_findXXX
	\item Inefficiencies of block array vs bitmaps
\end{itemize}

\subsection{Operations}

\textbf{XXX}---be very careful when attaching ops to different file types. I had page\_get\_link in inode operations that were attached to a regular file. I couldn't figure out why I was getting a panic in page\_get\_link() when dealing with a regular file. The stack trace was:

\begin{Verbatim}
[  198.626623] kernel BUG at fs/namei.c:5027!
[  198.627489] Internal error: Oops - BUG: 0 [#1] SMP
...
[  198.646732]  page_get_link+0x130/0x140
[  198.646875]  pick_link+0x340/0x400
[  198.646996]  step_into+0x290/0x3b0
[  198.647115]  open_last_lookups+0xc4/0x41c
[  198.647256]  path_openat+0x90/0x2c4
[  198.647379]  do_filp_open+0xb0/0x184
\end{Verbatim}

\noindent
nohighmem was not set for IFREG

\subsection{super\_operations}

The full list of super\_operations is huge:

XXX - Perhaps give an idea for what these do but cover them in more detail in the advanced book? For example, freeze/unfreeze only seem to be used for GFS

\begin{center}
\begin{tabular}{| l | l | c |}
\hline
\rowcolor[gray]{.9}\bf{Operation}&\bf{Used by SPFS}&\bf{Description} \\
\hline
alloc\_inode&this method is called by alloc\_inode() to allocate memory
 	for struct inode and initialize it.  If this function is not
 	defined, a simple 'struct inode' is allocated.  Normally
 	alloc\_inode will be used to allocate a larger structure which
 	contains a 'struct inode' embedded within it.&desc \\
\hline
destro\_inode&desc&yesno \\
\hline
free\_inode&desc&yesno \\
\hline
dirty\_inode&desc&yesno \\
\hline
write\_inode&Called when the kernel needs to write an inode to disk. The second parameter specifies whether the write should be synchronous or not. Not all filesystems check this flag.& yes! \\
\hline
drop\_inode&desc&yesno \\
\hline
evict\_inode&desc&yesno \\
\hline
put\_super&Called as part of \cf{umount} before the \cf{super\_block} will be freed.&yesno \\
\hline
sync\_fs&desc&yesno \\
\hline
freeze\_super&desc&yesno \\
\hline
freeze\_fs&desc&yesno \\
\hline
thaw\_super&desc&yesno \\
\hline
unfreeze\_fs&desc&yesno \\
\hline
statfs&desc&yesno \\
\hline
remount\_fs&desc&yesno \\
\hline
umount\_begin&desc&yesno \\
\hline
show\_options&desc&yesno \\
\hline
show\_devname&desc&yesno \\
\hline
show\_path&desc&yesno \\
\hline
show\_stats&desc&yesno \\
\hline
nr\_cached\_objects&desc&yesno \\
\hline
free\_cached\_objects&desc&yesno \\
\hline
quota\_read&desc&yesno \\
\hline
quota\_write&desc&yesno \\
\hline
get\_dquots&desc&yesno \\
\hline
\end{tabular}
\end{center}

\section{Notes}

MODULE\_ALIAS\_FS
MODULE\_ALIAS\_FS is defined un linux/fs.h as follows:

\#define MODULE\_ALIAS\_FS(NAME) MODULE\_ALIAS("fs-" NAME)

Seems like the goal is to load the module automatically when you do “mount -t spfs”. So how does that work?

\section{Implementing a User-based Filesystem}

\subsection{Improving Performance with eBPF}

xxx

\subsection{Installing FUSE}

On Ubuntu it's as simple as:

\begin{Verbatim}
    $ sudo apt install fuse
    $ sudo apt install libfuse-dev
\end{Verbatim}

\noindent
or do I need to install fuse3?

\subsection{Defining \cf{FUSE\_VERSION}}

\begin{Verbatim}
    #define FUSE_USE_VERSION 25
\end{Verbatim}

\subsection{Mounting the Filesystem}

Once the program has been compiled we can mount the filesystem as follows:

\begin{Verbatim}
    all:
	gcc -Wall spfs.c `pkg-config fuse --cflags --libs` -o spfs
\end{Verbatim}

\end{document}
